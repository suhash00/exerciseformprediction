---
title: "Predicting How Well People Exercise"
date: "April 3, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(caret)
library(parallel)
library(doParallel)
set.seed(100)
```

## Executive Summary

This project aims to predict the manner in which people exercise. Cross validation is used to split the training data into train and test sets to test and tune the model. The random forest algorithm is chosen to train the model as there are a large number of potential predictors and we don't know much about the relationships between them. The out of sample error is determined by applying the trained random forest model on the hold out data set (carved out separately from the training set and not used in training the model) and a model is chosen which provides a high prediction accuracy (more than 99%).   

## Exploratory Analysis

Let us load the training data set and look at the columns so we get a better understanding of the data set. Based on the analysis of the columns and the values (refer to Dataset Exploration in the Appendix), it looks like we can remove some columns which don't seem to be relevant to predicting exercise form and we can also remove columns that have primarily NA values as they will not be useful in the prediction. 

```{r exploratoryAnalysis}
# Load the training data set
exerciseData <- read.csv("C:/workspace/datascience/Practical Machine Learning/Course Assignment/pml-training.csv")

# Get the count of NAs in each column
countofNAs <- exerciseData %>% summarise_all(funs(sum(is.na(.))))

numberOfRows <- nrow(exerciseData)

# Find all cols that have more than 90% NAs
colsWithNAs <- apply(countofNAs, 2, function(x) (x/numberOfRows)*100 > 90)

# Drop the columns which have predominantly NAs
exerciseData <- exerciseData[, names(colsWithNAs[colsWithNAs==FALSE])]

# There are many columns which also have predominantly empty values. 
# Let us remove them as well.

countOfEmptyValues <- lapply(exerciseData, function(x) sum(x == ""))

# Find all columns that have mostly empty values and drop them as they will not be much helpful in our analysis and will make the model noisy

colsWithEmptyValues <- lapply(countOfEmptyValues, function(x) (if(is.na(x)) { TRUE }  else {(x/numberOfRows)*100 > 90}))
exerciseData <- exerciseData[, names(colsWithEmptyValues[colsWithEmptyValues==FALSE])]

# Also drop columns that may not be relevant to determining exercise form
colsToDrop <- c("X","user_name","raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp")
exerciseData <- exerciseData[, !names(exerciseData) %in% colsToDrop]
```
## Data Setup

We will be using k-fold cross validation to determine model accuracy and tune the model parameters. The k-fold cross validation will take care of splitting the data into training and test folds, so a separate testing data set is not required per se. But it would still be good to hold out a data set so we can revalidate the accuracy of the final trained model and the out of sample error.

```{r datasplit}
partition <- createDataPartition(y=exerciseData$classe, p = 0.8, list = FALSE)
# split the data into train and test data sets
trainData <- exerciseData[partition,]
testData <- exerciseData[-partition, ]

```

## Model Training

Considering that there are a large number of variables which can potentially be predictors and the fact that the relationship among the various variables may not be linear and very well understood, it may be better to go with a random forest model.

Since there are a large number of predictors, we can configure parallel processing to improve performance.

```{r parallelsetup}
cluster <- makeCluster(detectCores() - 1)
registerDoParallel(cluster)
```

Now let us set up the train control object with the method as cross-validation. 5 folds seems to be a good number of folds to strike a balance between not having too many or too few folds.

```{r crossvalidationsetup}
# setup the train control object with method cv and 5 folds
controlObj <- trainControl(method = "cv", number = 5, allowParallel = TRUE)

```

Now that we have the train control object defined, let us train the model using random forest as the method and the train control object as input for modelling.

```{r trainmodel}
# set the x and y variables to be used as input in the the train() method.
# x/y syntax is chosen as it gives a better performance as compared to the syntax with ~ format

x <- trainData[, ! names(trainData) %in% c("classe")]
y <- trainData[, names(trainData) %in% c("classe")]

# fit the training model

modFit <- train(x, y, method = "rf", trControl = controlObj)

# release the resources being used for parallel processing

stopCluster(cluster)
registerDoSEQ()

```

## Model Performance

Let us see how the trained model performs by comparing its predictions for the test set that we held out.

```{r prediction}
pred <- predict(modFit, testData)

# Check the accuracy of the prediction
confMatrix <- confusionMatrix(testData$classe, pred)
confMatrix$overall

# Calculate the out of sample error
ooserror <- 1 - confMatrix$overall['Accuracy']

```

As can be seen from the confusion matrix accuracy above, the accuracy of this model is very high. The **out of sample error** estimate for the model is only **`r ooserror`**. As we used a hold out data set instead of testing on the same data which was used for training, given the very low out of sample error estimate, we can conclude that the model is very robust and can be used for further predictions.

## Appendix

### Dataset Exploration

For the sake of brevity in the final report, the output of the command in this section has been suppressed.

```{r exploration, results = "hide"}
head(exerciseData)

```
From the output, it can be seen that there are some columns like obs, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp which may not be relevant to predicting how well people exercise.

Also there are many columns which seem to have predominantly NA columns. These NA columns will add little to no value to the prediction and can be dropped. Let us find the list of such columns.